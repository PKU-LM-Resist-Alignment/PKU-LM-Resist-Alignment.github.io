<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta content="Language Models Resist Alignment: Evidence From Data Compression" name="description" />
  <meta content="Language Models Resist Alignment: Evidence From Data Compression" property="og:title" />
  <meta content="Language Models Resist Alignment: Evidence From Data Compression" property="og:description" />
  <meta content="https://pku-lm-resist-alignment.github.io/data/open_graph.png" property="og:image" />
  <meta content="Language Models Resist Alignment" property="twitter:title" />
  <meta content="Language Models Resist Alignment" property="twitter:description" />
  <meta name="twitter:site" content="@jiaming_pku" />
  <meta name="twitter:creator" content="@jiaming_pku" />
  <meta content="https://pku-lm-resist-alignment.github.io/data/open_graph.png" property="twitter:image" />
  <meta property="og:type" content="website" />
  <meta content="summary_large_image" name="twitter:card" />
  <meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />

  <title>Language Models Resist Alignment: Evidence From Data Compression</title>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-9Z7HCWJNBC"></script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
  </script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', 'G-9Z7HCWJNBC');
  </script>
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link rel="preload" as="style"
    href="https://fonts.googleapis.com/css2?family=Asap:wght@700&family=Source+Sans+3:wght@400;700&display=swap">
  <link rel="stylesheet"
    href="https://fonts.googleapis.com/css2?family=Asap:wght@700&family=Source+Sans+3:wght@400;700&display=swap">
  <link href="style.css" rel="stylesheet" type="text/css" />
  <style>
    .experiment-table {
      width: 100%;
      border-collapse: collapse;
      margin: 20px 0;
      font-size: 14px;
    }
    .experiment-table th,
    .experiment-table td {
      border: 1px solid #ddd;
      padding: 8px;
      text-align: center;
    }
    .experiment-table th {
      background-color: #f2f2f2;
      font-weight: bold;
    }
    .experiment-table tr:nth-child(even) {
      background-color: #f9f9f9;
    }
    .forward {
      color: #548235;
      font-weight: bold;
    }
    .inverse {
      color: #2F5597;
      font-weight: bold;
    }
    .resist {
      color: #800080;
      font-style: italic;
    }
    .rebound {
      color: #851321;
      font-style: italic;
    }
    .experiment-section {
      margin: 40px 0;
    }
    
    /* Left Sidebar Navigation */
    .left-sidebar {
      position: fixed;
      left: 0;
      top: 70px;
      width: 300px;
      height: calc(100vh - 70px);
      background: linear-gradient(135deg, #f8f9fa 0%, #ffffff 100%);
      border-right: 2px solid #e9ecef;
      box-shadow: 2px 0 10px rgba(0, 0, 0, 0.15);
      overflow-y: auto;
      z-index: 1001;
      padding: 20px 0;
      transition: transform 0.3s ease;
    }
    
    .left-sidebar::-webkit-scrollbar {
      width: 6px;
    }
    
    .left-sidebar::-webkit-scrollbar-track {
      background: #f1f1f1;
    }
    
    .left-sidebar::-webkit-scrollbar-thumb {
      background: #c1c1c1;
      border-radius: 3px;
    }
    
    .left-sidebar::-webkit-scrollbar-thumb:hover {
      background: #a1a1a1;
    }
    
    .left-sidebar.open {
      transform: translateX(0);
    }
    
    .sidebar-header {
      padding: 0 20px 15px 20px;
      border-bottom: 2px solid #e9ecef;
      margin-bottom: 20px;
    }
    
    .sidebar-title {
      font-size: 16px;
      font-weight: 700;
      color: #2F5597;
      margin: 0;
      text-align: center;
    }
    
    .sidebar-nav {
      list-style: none;
      margin: 0;
      padding: 0;
    }
    
    .sidebar-nav > li {
      margin-bottom: 8px;
    }
    
    .sidebar-nav a {
      display: block;
      padding: 10px 20px;
      color: #333;
      text-decoration: none;
      font-weight: 500;
      font-size: 14px;
      transition: all 0.3s ease;
      border-left: 3px solid transparent;
      position: relative;
    }
    
    .sidebar-nav a:hover {
      background-color: rgba(47, 85, 151, 0.1);
      color: #2F5597;
      border-left-color: #2F5597;
    }
    
    .sidebar-nav a.active {
      background-color: rgba(47, 85, 151, 0.15);
      color: #2F5597;
      border-left-color: #2F5597;
      font-weight: 600;
    }
    
    .sidebar-nav a.main-section {
      font-weight: 600;
      font-size: 15px;
      color: #2F5597;
      text-transform: uppercase;
      letter-spacing: 0.5px;
      margin-top: 10px;
      padding-bottom: 8px;
    }
    
    .sidebar-nav a.sub-section {
      padding-left: 35px;
      font-size: 13px;
      color: #666;
      font-weight: 400;
    }
    
    .sidebar-nav a.sub-sub-section {
      padding-left: 50px;
      font-size: 12px;
      color: #777;
      font-weight: 400;
    }
    
    .sidebar-nav a.main-section:hover,
    .sidebar-nav a.main-section.active {
      background-color: rgba(47, 85, 151, 0.2);
    }
    
    .sidebar-nav a.sub-section:hover,
    .sidebar-nav a.sub-section.active {
      background-color: rgba(47, 85, 151, 0.1);
      color: #2F5597;
    }
    
    .sidebar-nav a.sub-sub-section:hover,
    .sidebar-nav a.sub-sub-section.active {
      background-color: rgba(47, 85, 151, 0.08);
      color: #2F5597;
    }
    
    /* Content adjustment for sidebar */
    .main-content {
      margin-left: 0;
      transition: margin-left 0.3s ease;
    }
    
    /* Sidebar toggle button */
    .sidebar-toggle {
      position: fixed;
      left: 20px;
      top: 50%;
      transform: translateY(-50%);
      background: #2F5597;
      color: white;
      border: none;
      width: 40px;
      height: 40px;
      border-radius: 50%;
      font-size: 18px;
      cursor: pointer;
      box-shadow: 0 4px 12px rgba(47, 85, 151, 0.3);
      z-index: 1001;
      display: none;
      transition: all 0.3s ease;
    }
    
    .sidebar-toggle:hover {
      background: #1a3f7a;
      transform: translateY(-50%) scale(1.1);
    }
    
    .sidebar-toggle.visible {
      display: block;
    }
    
    /* Mobile responsive */
    @media (max-width: 1024px) {
      .left-sidebar {
        transform: translateX(-100%);
      }
      
      .left-sidebar.open {
        transform: translateX(0);
      }
      
      .sidebar-toggle {
        display: block;
      }
    }
    
    @media (max-width: 768px) {
      .left-sidebar {
        width: 260px;
      }
      
      .sidebar-toggle {
        left: 15px;
        width: 35px;
        height: 35px;
        font-size: 16px;
      }
    }

    /* Theory Section Styles */
    .theory-container {
      position: relative;
      margin: 30px 0;
      min-height: 600px;
    }
    .theory-list {
      width: 100%;
      max-width: none;
      padding-right: 20px; /* Leave space for the proof panel */
    }
    .theory-item {
      background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
      border: 2px solid #dee2e6;
      border-radius: 12px;
      padding: 20px;
      margin: 20px 0;
      position: relative;
      transition: all 0.3s ease;
      cursor: pointer;
    }
    .theory-item:hover {
      border-color: #2F5597;
      box-shadow: 0 8px 25px rgba(47, 85, 151, 0.15);
      transform: translateY(-2px);
    }
    .theory-item.active {
      border-color: #2F5597;
      box-shadow: 0 12px 35px rgba(47, 85, 151, 0.2);
      background: linear-gradient(135deg, #f5fbff 0%, #ebf7fa 100%);
    }
    .theory-header {
      display: flex;
      justify-content: space-between;
      align-items: center;
      margin-bottom: 15px;
    }
    .theory-title {
      font-size: 18px;
      font-weight: 700;
      color: #2F5597;
      margin: 0;
    }
    .proof-btn {
      background: linear-gradient(135deg, #2F5597 0%, #4a6bb8 100%);
      color: white;
      border: none;
      padding: 8px 16px;
      border-radius: 20px;
      font-size: 12px;
      font-weight: 600;
      cursor: pointer;
      transition: all 0.3s ease;
      text-transform: uppercase;
      letter-spacing: 0.5px;
    }
    .proof-btn:hover {
      background: linear-gradient(135deg, #1a3f7a 0%, #2F5597 100%);
      transform: scale(1.05);
      box-shadow: 0 4px 15px rgba(47, 85, 151, 0.3);
    }
    .theory-content {
      color: #333;
      line-height: 1.6;
    }
    .proof-panel {
      position: fixed;
      right: 2%;
      top: 120px;
      width: 22%;
      height: calc(100vh - 140px);
      overflow-y: auto;
      z-index: 100;
    }
    .proof-container {
      background: #fff;
      border: 2px solid #e9ecef;
      border-radius: 12px;
      padding: 25px;
      box-shadow: 0 10px 30px rgba(0, 0, 0, 0.1);
      min-height: 400px;
      transition: all 0.3s ease;
    }
    .proof-container.active {
      border-color: #2F5597;
      box-shadow: 0 15px 40px rgba(47, 85, 151, 0.15);
    }
    .proof-container.active.definition-active {
      border-color: #6c757d;
      box-shadow: 0 15px 40px rgba(108, 117, 125, 0.15);
    }
    .proof-header {
      font-size: 20px;
      font-weight: 700;
      color: #2F5597;
      margin-bottom: 20px;
      padding-bottom: 10px;
      border-bottom: 2px solid #e9ecef;
    }
    .proof-header.definition-header {
      color: #6c757d;
    }
    .proof-content {
      color: #333;
      line-height: 1.7;
      font-size: 14px;
    }
    .proof-placeholder {
      text-align: center;
      color: #6c757d;
      font-style: italic;
      margin-top: 150px;
    }
    .math-block {
      background: #f8f9fa;
      border-left: 4px solid #2F5597;
      padding: 15px;
      margin: 15px 0;
      border-radius: 5px;
      overflow-x: auto;
    }
    .math-block.definition-math {
      border-left: 4px solid #6c757d;
    }
    .definition-box {
      background: transparent;
      border: none;
      padding: 15px;
      margin: 15px 0;
      border-radius: 5px;
    }
    .theorem-box {
      background: transparent;
      border: none;
      padding: 15px;
      margin: 15px 0;
      border-radius: 5px;
    }
    .assumption-box {
      background: transparent;
      border: none;
      padding: 15px;
      margin: 15px 0;
      border-radius: 5px;
    }
    .theory-title.definition {
      color: #6c757d;
    }
    .theory-title.theorem {
      color: #2F5597;
    }
    .theory-title.assumption {
      color: #dc3545;
    }
    
    /* Definition specific styles (gray theme) */
    .theory-item[data-theory^="token-tree"] .proof-btn,
    .theory-item[data-theory^="compression-protocol"] .proof-btn,
    .theory-item[data-theory^="inverse-alignment"] .proof-btn,
    .theory-item[data-theory^="elasticity-definition"] .proof-btn,
    .theory-item[data-theory^="normalized-compression"] .proof-btn {
      background: linear-gradient(135deg, #6c757d 0%, #8a9196 100%);
    }
    .theory-item[data-theory^="token-tree"] .proof-btn:hover,
    .theory-item[data-theory^="compression-protocol"] .proof-btn:hover,
    .theory-item[data-theory^="inverse-alignment"] .proof-btn:hover,
    .theory-item[data-theory^="elasticity-definition"] .proof-btn:hover,
    .theory-item[data-theory^="normalized-compression"] .proof-btn:hover {
      background: linear-gradient(135deg, #495057 0%, #6c757d 100%);
      box-shadow: 0 4px 15px rgba(108, 117, 125, 0.3);
    }
    .theory-item[data-theory^="token-tree"]:hover,
    .theory-item[data-theory^="compression-protocol"]:hover,
    .theory-item[data-theory^="inverse-alignment"]:hover,
    .theory-item[data-theory^="elasticity-definition"]:hover,
    .theory-item[data-theory^="normalized-compression"]:hover {
      border-color: #6c757d;
      box-shadow: 0 8px 25px rgba(108, 117, 125, 0.15);
    }
    .theory-item[data-theory^="token-tree"].active,
    .theory-item[data-theory^="compression-protocol"].active,
    .theory-item[data-theory^="inverse-alignment"].active,
    .theory-item[data-theory^="elasticity-definition"].active,
    .theory-item[data-theory^="normalized-compression"].active {
      border-color: #6c757d;
      box-shadow: 0 12px 35px rgba(108, 117, 125, 0.2);
      background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
    }
    
    /* Theorem specific styles (blue theme) */
    .theory-item[data-theory^="ideal-code-length"] .proof-btn,
    .theory-item[data-theory^="main-theorem"] .proof-btn {
      background: linear-gradient(135deg, #2F5597 0%, #4a6bb8 100%);
    }
    .theory-item[data-theory^="ideal-code-length"] .proof-btn:hover,
    .theory-item[data-theory^="main-theorem"] .proof-btn:hover {
      background: linear-gradient(135deg, #1a3f7a 0%, #2F5597 100%);
      box-shadow: 0 4px 15px rgba(47, 85, 151, 0.3);
    }
    .theory-item[data-theory^="ideal-code-length"]:hover,
    .theory-item[data-theory^="main-theorem"]:hover {
      border-color: #2F5597;
      box-shadow: 0 8px 25px rgba(47, 85, 151, 0.15);
    }
    .theory-item[data-theory^="ideal-code-length"].active,
    .theory-item[data-theory^="main-theorem"].active {
      border-color: #2F5597;
      box-shadow: 0 12px 35px rgba(47, 85, 151, 0.2);
      background: linear-gradient(135deg, #f5fbff 0%, #ebf7fa 100%);
    }
    @media (max-width: 1024px) {
      .theory-list {
        width: 100%;
        padding-right: 0;
      }
      .proof-panel {
        position: static;
        width: 100%;
        height: auto;
        margin-top: 30px;
        right: auto;
        top: auto;
      }
    }
    .experiment-grid {
      display: grid;
      grid-template-columns: 1fr 1fr;
      gap: 20px;
      margin: 20px 0;
    }
    .experiment-vertical {
      display: grid;
      grid-template-columns: 1fr;
      gap: 20px;
      margin: 20px 0;
    }
    .experiment-item {
      text-align: center;
    }
    .experiment-item img {
      max-width: 100%;
      height: auto;
      border: 1px solid #ddd;
      border-radius: 8px;
    }
    
    /* Main GIF Styles */
    .main-gif-container {
      margin: 40px 0;
      display: flex;
      justify-content: center;
      align-items: center;
    }
    
    .gif-wrapper {
      text-align: center;
      background: linear-gradient(135deg, #f8f9fa 0%, #ffffff 100%);
      border: 2px solid #e9ecef;
      border-radius: 16px;
      padding: 30px;
      box-shadow: 0 10px 30px rgba(0, 0, 0, 0.1);
      transition: all 0.3s ease;
      max-width: 800px;
      width: 100%;
    }
    
    .gif-wrapper:hover {
      border-color: #2F5597;
      box-shadow: 0 15px 40px rgba(47, 85, 151, 0.15);
      transform: translateY(-3px);
    }
    
    .main-gif {
      max-width: 100%;
      height: auto;
      border-radius: 12px;
      box-shadow: 0 8px 25px rgba(0, 0, 0, 0.1);
      transition: all 0.3s ease;
    }
    
    .main-gif:hover {
      box-shadow: 0 12px 35px rgba(0, 0, 0, 0.15);
    }
    
    .gif-caption {
      margin-top: 20px;
      font-size: 16px;
      color: #2F5597;
      font-weight: 600;
      font-style: italic;
      letter-spacing: 0.3px;
    }
    
    /* Responsive design for main gif */
    @media (max-width: 768px) {
      .main-gif-container {
        margin: 30px 0;
      }
      
      .gif-wrapper {
        padding: 20px;
        margin: 0 10px;
      }
      
      .gif-caption {
        font-size: 14px;
        margin-top: 15px;
      }
    }
    
    @media (max-width: 480px) {
      .gif-wrapper {
        padding: 15px;
        border-radius: 12px;
      }
      
      .main-gif {
        border-radius: 8px;
      }
    }
    .key-finding {
      background-color: #e8f4fd;
      padding: 15px;
      border-left: 4px solid #2F5597;
      margin: 20px 0;
    }
    .key-finding.definition-finding {
      background-color: #f8f9fa;
      border-left: 4px solid #6c757d;
    }
    /* Navigation styles */
    .navbar {
      position: fixed;
      top: 0;
      left: 0;
      right: 0;
      background-color: rgba(255, 255, 255, 0.95);
      backdrop-filter: blur(10px);
      border-bottom: 1px solid #e0e0e0;
      z-index: 1000;
      padding: 10px 0;
      transition: all 0.3s ease;
    }
    .navbar.scrolled {
      box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
    }
    .nav-container {
      max-width: 1200px;
      margin: 0 auto;
      display: flex;
      justify-content: space-between;
      align-items: center;
      padding: 0 20px;
    }
    .nav-logo {
      font-size: 18px;
      font-weight: bold;
      color: #2F5597;
      text-decoration: none;
    }
    .nav-links {
      display: flex;
      list-style: none;
      margin: 0;
      padding: 0;
      gap: 30px;
    }
    .nav-links a {
      text-decoration: none;
      color: #333;
      font-weight: 500;
      transition: color 0.3s ease;
      position: relative;
    }
    .nav-links a:hover {
      color: #2F5597;
    }
    .nav-links a.active {
      color: #2F5597;
    }
    .nav-links a::after {
      content: '';
      position: absolute;
      width: 0;
      height: 2px;
      bottom: -5px;
      left: 50%;
      background-color: #2F5597;
      transition: all 0.3s ease;
      transform: translateX(-50%);
    }
    .nav-links a:hover::after,
    .nav-links a.active::after {
      width: 100%;
    }
    /* Mobile menu styles */
    .mobile-menu-toggle {
      display: none;
      background: none;
      border: none;
      font-size: 24px;
      cursor: pointer;
      color: #333;
    }
    .section {
      padding-top: 80px; /* Add space for fixed navbar */
    }
    /* Mobile responsive */
    @media (max-width: 768px) {
      .nav-links {
        display: none;
        position: absolute;
        top: 100%;
        left: 0;
        right: 0;
        background-color: white;
        flex-direction: column;
        gap: 0;
        box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
        padding: 20px;
      }
      .nav-links.active {
        display: flex;
      }
      .nav-links a {
        padding: 10px 0;
        border-bottom: 1px solid #eee;
      }
      .mobile-menu-toggle {
        display: block;
      }
    }
  </style>
</head>

<body>
  <!-- Left Sidebar Navigation -->
  <div class="left-sidebar" id="left-sidebar">
    <div class="sidebar-header">
      <h3 class="sidebar-title">Contents</h3>
    </div>
    <nav>
      <ul class="sidebar-nav">
        <li><a href="#top" class="main-section">Title</a></li>
        <li><a href="#overview" class="main-section">Overview</a></li>
        <li><a href="#theory" class="main-section">Theory</a></li>
        <li><a href="#token-tree" class="sub-section">Token Tree</a></li>
        <li><a href="#compression-protocol" class="sub-section">Compression Protocol</a></li>
        <li><a href="#ideal-code-length" class="sub-section">Ideal Code Length</a></li>
        <li><a href="#inverse-alignment" class="sub-section">Inverse Alignment</a></li>
        <li><a href="#elasticity-definition" class="sub-section">Elasticity Definition</a></li>
        <li><a href="#normalized-compression" class="sub-section">Normalized Compression</a></li>
        <li><a href="#main-theorem" class="sub-section">Main Theorem</a></li>
        <li><a href="#experiments" class="main-section">Experiments</a></li>
        <li><a href="#resistance-experiment" class="sub-section">Resistance Evidence</a></li>
        <li><a href="#rebound-experiment" class="sub-section">Rebound Evidence</a></li>
        <li><a href="#model-size-experiment" class="sub-section">Model Size Impact</a></li>
        <li><a href="#data-volume-experiment" class="sub-section">Data Volume Impact</a></li>
        <li><a href="#insights" class="main-section">Insights</a></li>
        <li><a href="#impact" class="main-section">Impact</a></li>
        <li><a href="#citation" class="main-section">Citation</a></li>
      </ul>
    </nav>
  </div>

  <!-- Sidebar Toggle Button -->
  <button class="sidebar-toggle" id="sidebar-toggle">☰</button>

  <!-- Navigation Bar -->
  <nav class="navbar" id="navbar">
    <div class="nav-container">
      <a href="#top" class="nav-logo">Language Models Resist Alignment</a>
      <ul class="nav-links" id="nav-links">
        <li><a href="#overview" data-section="overview">Overview</a></li>
        <li><a href="#theory" data-section="theory">Theory</a></li>
        <li><a href="#experiments" data-section="experiments">Experiments</a></li>
        <li><a href="#insights" data-section="insights">Insights</a></li>
        <li><a href="#impact" data-section="impact">Impact</a></li>
        <li><a href="#citation" data-section="citation">Citation</a></li>
      </ul>
      <button class="mobile-menu-toggle" id="mobile-toggle">☰</button>
    </div>
  </nav>

  <div class="main-content">
  <div class="section" id="top">
    <div class="container">
      <div class="title-row">
        <h1 class="title">Language Models Resist Alignment: Evidence From Data Compression<h1>
      </div>
      <div class="row">
        <div class="author-col">
          <a href="https://jijiaming.com/" target="_blank" class="author-text">
            Jiaming Ji*
          </a>
        </div>
        <div class="author-col">
          <a href="https://scholar.google.com.hk/citations?user=hTNgG1YAAAAJ" target="_blank" class="author-text">
            Kaile Wang*
          </a>
        </div>
        <div class="author-col">
          <a href="https://tianyiqiu.net" target="_blank" class="author-text">
            Tianyi Qiu*
          </a>
        </div>
        <div class="author-col">
          <a href="https://cby-pku.github.io/" target="_blank" class="author-text">
            Boyuan Chen<span class="superscript">*</span>
          </a>
        </div>
        <div class="author-col">
          <a href="https://gaiejj.github.io" target="_blank" class="author-text">
            Jiayi Zhou*
          </a>
        </div>
      </div>
      <div class="row">
        <div class="author-col">
          <a class="author-text">
            Changye Li
          </a>
        </div>
        <div class="author-col">
          <a class="author-text">
            Hantao Lou
          </a>
        </div>
        <div class="author-col">
          <a class="author-text">
            Juntao Dai
          </a>
        </div>
        <div class="author-col">
          <a class="author-text">
            Yunhuai Liu
          </a>
        </div>
        <div class="author-col">
          <a href="https://www.yangyaodong.com/" target="_blank" class="author-text">
            Yaodong Yang<span class="superscript">†</span>
          </a>
        </div>
      </div>

    </div>
    <p id="uc-berkeley">Peking University</h1>

    <div class="row button-row">
      <a class="link-button" href="https://arxiv.org/abs/2406.06144" target="_blank" class="link-block">Paper</a>
      <a class="link-button" href="https://github.com/PKU-Alignment/llms-resist-alignment" class="link-block">Code</a>
      <a class="link-button"
        href="https://huggingface.co/collections/PKU-Alignment/language-model-resist-alignment-683aa526612e76702e7651ae"
        class="link-block">Models</a>
    </div>

    <p class="tldr">
      <b>TL;DR</b>:
      We demonstrate the elasticity of post-alignment models, forming resistance to alignment.
    </p>

    <!-- Main GIF Demonstration -->
    <div class="main-gif-container">
      <div class="gif-wrapper">
        <img src="resist_main.gif" alt="Language Model Resistance Demonstration" class="main-gif">
        <p class="gif-caption">Visual demonstration of language model resistance to alignment</p>
      </div>
    </div>

    <div class="key-finding">
      <h3>Key Finding: The Elasticity of Language Models</h3>
      <p>Language models exhibit <strong>elasticity</strong> - an inherent tendency to retain original distributions and resist alignment modifications. This phenomenon encompasses:</p>
      <ul>
        <li><span class="resist"><strong>Resistance</strong></span>: Pre-trained models tend to maintain their original distribution</li>
        <li><span class="rebound"><strong>Rebound</strong></span>: The deeper the alignment, the faster models return to pre-training distribution under reverse fine-tuning</li>
      </ul>
    </div>

    <div id="content">
      <h2 class="section-header" id="overview">Overview</h2>
      <div class="paragraph">
        <p>
          Large language models (LLMs) may exhibit unintended or undesirable behaviors. Recent works have concentrated
          on aligning LLMs to mitigate harmful outputs. Despite these efforts, some anomalies indicate that even a
          well-conducted alignment process can be easily circumvented, whether intentionally or accidentally. Does
          alignment fine-tuning yield have robust effects on models, or are its impacts merely
          <i><b>superficial?</b></i> In
          this work, we make the first exploration of this phenomenon from both theoretical and empirical perspectives.
          Empirically, we demonstrate the <i><b>elasticity</b></i> of post-alignment models, <i>i.e.</i>, the tendency
          to
          revert to the behavior distribution formed during the pre-training phase upon further fine-tuning. Leveraging
          compression theory, we formally deduce that fine-tuning disproportionately undermines alignment
          relative to pre-training, potentially by orders of magnitude. We validate the presence of <i>elasticity</i>
          through experiments on models of varying types and scales. Specifically, we find that model performance
          declines rapidly before reverting to the pre-training
          distribution, after which the rate of decline drops significantly. Furthermore, we further reveal that
          <i>elasticity</i> positively correlates with the increased model size
          and the expansion of pre-training data. Our findings underscore the need to address the inherent
          <i>elasticity</i> of LLMs to mitigate their
          resistance to alignment.
        </p>
        <p><b>Contributions:</b></p>
        <ul>
          <li>
            <b>Phenomenon:</b> we uncover that language models exhibit <i>elasticity</i>. It encompasses
            <span class="resist">resistance</span>: pre-trained models tend
            to retain their original distribution; and <span class="rebound">rebound</span>: the deeper alignment of
            models, the faster
            they return to the pre-trained distribution under reverse finetuning. Moreover, The model's change in
            compression rates \(\Delta \gamma_{p_\mathbf{\theta}}^{\mathcal{D}_i/\mathcal{D}}\) across
            different datasets is inversely proportional to their sizes \(|\mathcal{D}_i|\), which is
            analogous to the deformation behavior of a series of springs.

          </li>
          <li>
            <b>Mechanism:</b> We systematically model the training and alignment process of language models through
            compression theorem. We elaborate on the compression
            protocol of language models to explore their training and alignment processes, laying a foundation for
            subsequent research on <i>elasticity</i>.
          </li>
          <li>
            <b>Validation:</b> We experimentally observe consistent resistance and rebound phenomena
            across various LLMs. This highlights the universality of elasticity and the need for systematic approaches
            to achieve robust and deep alignment.
          </li>
        </ul>
      </div>

    <div id="content">
      
      <h2 class="section-header" id="theory">Theoretical Framework</h2>
      <div class="paragraph">
        <p>
          Our theoretical analysis builds upon compression theory to formally characterize the <i>elasticity</i> phenomenon in language models. Below are the key definitions and theorems that form the foundation of our work.
        </p>
      </div>

      <div class="theory-container">
        <div class="theory-list">
          
          <div class="theory-item" data-theory="token-tree" id="token-tree">
            <div class="theory-header">
              <h3 class="theory-title definition">Definition 1: Token Tree 𝒯</h3>
              <button class="proof-btn" onclick="showProof('token-tree')">View Details</button>
            </div>
            <div class="theory-content definition-box">
              <p>For a dataset \(\mathcal{D} = \{ \mathbf{z}_{i} \in \{0|1\}^{\infty} \mid i = 1,2, \cdots \}\), the token tree of \(\mathcal{D}\), denoted as \(\mathcal{T}_{\mathcal{D}}\), is defined as follows: each node has child nodes labeled <code>0</code> or <code>1</code>, along with an end-of-sequence (EOS) leaf node. The path from the root to a leaf node defines each response \(\mathbf{z}_{i}\), with the corresponding EOS node weight representing the response's probability while the weight of non-leaf nodes is the sum of the weights of their child nodes.</p>
            </div>
          </div>

          <div class="theory-item" data-theory="compression-protocol" id="compression-protocol">
            <div class="theory-header">
              <h3 class="theory-title definition">Definition 2: The Compression Protocol</h3>
              <button class="proof-btn" onclick="showProof('compression-protocol')">View Details</button>
            </div>
            <div class="theory-content definition-box">
              <p>Consider using the model \(p_{\mathbf{\theta}}\left(\cdot\right)\) to compress the dataset \(\mathcal{D}\). The compression protocol is defined in two steps:</p>
              <ol>
                <li><strong>Prune</strong> the token tree of \(\mathcal{D}\), retaining only the top \(d\) layers.</li>
                <li><strong>Apply Huffman coding</strong> to compress the pruned token tree. Each response from the root node to a leaf node is treated as a symbol in the Huffman coding alphabet, and the weight of the leaf node is the probability of the symbol.</li>
              </ol>
            </div>
          </div>

          <div class="theory-item" data-theory="ideal-code-length" id="ideal-code-length">
            <div class="theory-header">
              <h3 class="theory-title theorem">Theorem 1: Ideal Code Length</h3>
              <button class="proof-btn" onclick="showProof('ideal-code-length')">View Proof</button>
            </div>
            <div class="theory-content theorem-box">
              <p>Consider a finite parameter model \(p_{\mathbf{\theta}}\left(\cdot\right)\) training on dataset \(\mathcal{D}\), the ideal code length \(\mathcal{L}_{p_{\mathbf{\theta}}}\left(\mathbf{x}\right)\) of a random response \(\mathbf{x}\) compressed by \(p_{\mathbf{\theta}}\) can be expressed as:</p>
              <div class="math-block">
                \[\mathbb{E}\left[\mathcal{L}_{p_{\mathbf{\theta}}}\left(\mathbf{x}\right)\right] = \left\lceil\frac{\big|\mathbf{x}\big|}{d}\right\rceil\left\lceil-\sum_{l=1}^{d}\sum_{j=1}^{2^{l-1}}p_{lj}\log{p_{lj}}\right\rceil\]
              </div>
              <p>where \(d\) represents the depth of the \(\mathcal{T}_{\mathcal{D}}\) after pruning and \(p_{lj}\) represents the probability values of the leaf nodes for the \(j\)-th node at the \(l\)-th layer.</p>
            </div>
          </div>

          <div class="theory-item" data-theory="inverse-alignment" id="inverse-alignment">
            <div class="theory-header">
              <h3 class="theory-title definition">Definition 3: Inverse Alignment</h3>
              <button class="proof-btn" onclick="showProof('inverse-alignment')">View Details</button>
            </div>
            <div class="theory-content definition-box">
              <p>Given a language model \(p_{\mathbf{\theta}_0}\), aligned on dataset \(\mathcal{D}_{a}\) to produce the aligned model \(p_{\mathbf{\theta}_1}\). For any \(\epsilon > 0\), if applying a dataset \(\mathcal{D}_{b}\) (where \(|\mathcal{D}_{b}| \ll |\mathcal{D}_{a}|\)) to \(p_{\mathbf{\theta}_1}\) yields \(p_{\mathbf{\theta}_0^{\prime}}\) such that \(\rho(p_{\mathbf{\theta}_0^{\prime}}, p_{\mathbf{\theta}_0}) \leq \epsilon\) for a given eval metric \(\rho\), we define the transition from \(p_{\mathbf{\theta}_1}\) back to \(p_{\mathbf{\theta}_0^{\prime}}\) as <i>inverse alignment</i>.</p>
            </div>
          </div>

          <div class="theory-item" data-theory="elasticity-definition" id="elasticity-definition">
            <div class="theory-header">
              <h3 class="theory-title definition">Definition 4: The Elasticity of LLMs</h3>
              <button class="proof-btn" onclick="showProof('elasticity-definition')">View Details</button>
            </div>
            <div class="theory-content definition-box">
              <p>Consider a language model \(p_{\mathbf{\theta}_0}\) and transformation \(p_{\mathbf{\theta}_0} \xmapsto{f(\mathcal{D}_a)} p_{\mathbf{\theta}_1}\), <i>elasticity</i> is said to exist in \(\left(p_{\mathbf{\theta}_0},\mathcal{D}_a\right)\) if there is an algorithmically simple <i>inverse operation</i> \(g\) and a dataset \(\mathcal{D}_b\) such that \(|\mathcal{D}_b| \ll |\mathcal{D}_a|\), with the property that:</p>
              <div class="math-block">
                \[p_{\mathbf{\theta}_1} \xmapsto{g(\mathcal{D}_b)} p_{\mathbf{\theta}_0^{\prime}} \text{ and } \rho(p_{\mathbf{\theta}_0^{\prime}}, p_{\mathbf{\theta}_0}) \leq \epsilon_0\]
              </div>
              <p>where \(\epsilon_0\) is a constant.</p>
            </div>
          </div>

          <div class="theory-item" data-theory="normalized-compression" id="normalized-compression">
            <div class="theory-header">
              <h3 class="theory-title definition">Definition 5: Normalized Compression Rate</h3>
              <button class="proof-btn" onclick="showProof('normalized-compression')">View Details</button>
            </div>
            <div class="theory-content definition-box">
              <p>For \(N\) pairwise disjoint datasets \(\mathcal{D}_{1}, \cdots, \mathcal{D}_{N}\) and a parameter model \(p_{\mathbf{\theta}}\) compressing \(\mathcal{D}=\bigcup_{i=1}^{N}\mathcal{D}_{i}\), the normalized compression rate \(\gamma_{p_{\mathbf{\theta}}}^{\mathcal{D}_{i}/\mathcal{D}}\) for a particular dataset \(\mathcal{D}_{i}\) is defined as:</p>
              <div class="math-block">
                \[\gamma_{p_{\mathbf{\theta}}}^{\mathcal{D}_{i}/\mathcal{D}} = \gamma_{p_{\mathbf{\theta}}}^{\mathcal{D}_{i}} - \log{M}\]
              </div>
              <p>where \(M\) is the number of leaf nodes of the pruned tree \(\mathcal{T}_{i}^{\prime}\) of dataset \(\mathcal{D}_{i}\).</p>
            </div>
          </div>

          <div class="theory-item" data-theory="main-theorem" id="main-theorem">
            <div class="theory-header">
              <h3 class="theory-title theorem">Theorem 2: Elasticity of Language Models</h3>
              <button class="proof-btn" onclick="showProof('main-theorem')">View Proof</button>
            </div>
            <div class="theory-content theorem-box">
              <p>Consider the pre-training dataset \(\mathcal{D}_p = \bigcup_{i=1}^{3}\mathcal{D}_{i}\), the alignment dataset \(\mathcal{D}_a\), and the perturbation dataset \(\mathcal{D}_t\), with the model \(p_{\boldsymbol{\theta}}(\cdot)\) trained on \(\mathcal{D}=\mathcal{D}_{p} \cup \mathcal{D}_{a} \cup \mathcal{D}_{t}\). Assume that \(\mathcal{D}_a \overset{d}{\sim} \mathcal{D}_{2}\), \(\mathcal{D}_t \overset{d}{\sim} \mathcal{D}_{3}\), and \(\mathcal{D}_{1},\mathcal{D}_{2},\mathcal{D}_{3}\) are each distributed according to a Pareto mass distribution. As the perturbation data volume \(|\mathcal{D}_t|\) varies, \(\gamma_{p_{\boldsymbol{\theta}}}^{\mathcal{D}_p/\mathcal{D}}\) and \(\gamma_{p_{\boldsymbol{\theta}}}^{\mathcal{D}_a/\mathcal{D}}\) satisfy:</p>
              <div class="math-block">
                \[\begin{align}
                \frac{d\gamma_{p_{\boldsymbol{\theta}}}^{\mathcal{D}_a/\mathcal{D}}}{d\,l} &= \Theta \left( -k \frac{ d\gamma_{p_{\boldsymbol{\theta}}}^{\mathcal{D}_p/\mathcal{D}}}{d\,l} \right),\\
                \frac{d\gamma_{p_{\boldsymbol{\theta}}}^{\mathcal{D}_p/\mathcal{D}}}{d\,l} &< 0,\\
                \frac{d\gamma_{p_{\boldsymbol{\theta}}}^{\mathcal{D}_a/\mathcal{D}}}{d\,l} &> 0,
                \end{align}\]
              </div>
              <p>where \(l = \frac{|\mathcal{D}_t|}{|\mathcal{D}_a|} \ll 1\), \(k = \frac{|\mathcal{D}_p|}{|\mathcal{D}_a|} \gg 1\), and \(\{\mathcal{D}_{i}\}_{i=1}^3\) are datasets of equal cardinality.</p>
            </div>
          </div>

        </div>

        <div class="proof-panel">
          <div class="proof-container" id="proof-container">
            <div class="proof-placeholder">
              <h3>🔍 Interactive Proofs</h3>
              <p>Click on the "View Proof" or "View Details" buttons to explore the theoretical foundations of language model elasticity.</p>
            </div>
          </div>
        </div>
      </div>
      
      <h2 class="section-header" id="experiments">Experimental Validation</h2>
      
      <div class="experiment-section" id="resistance-experiment">
        <h3>1. Evidence of <span class="resist">Resistance</span> Phenomenon</h3>
        <div class="paragraph">
          We validate that <span class="inverse">inverse alignment</span> is consistently easier than <span class="forward">forward alignment</span> across different models and datasets. The experimental setup compares training loss when moving between different alignment states.
        </div>
        
        <img class="wide-img" src="static/images/exm_images/exp1_recon.png" alt="Resistance Experiment Pipeline" style="max-width: 500px; margin: 20px auto; display: block;">
        
        <table class="experiment-table">
          <caption><strong>Comparison between Inverse and Forward Alignment Training Loss</strong></caption>
          <thead>
            <tr>
              <th rowspan="2">Datasets</th>
              <th rowspan="2">Base Models</th>
              <th colspan="3">Training Loss Comparison</th>
            </tr>
            <tr>
              <th>θ₂ → θ₁ vs. θ₁ → θ₂</th>
              <th>θ₃ → θ₂ vs. θ₂ → θ₃</th>
              <th>θ₃ → θ₁ vs. θ₁ → θ₃</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="3"><strong>Alpaca</strong></td>
              <td>Llama2-7B</td>
              <td><span class="inverse">0.1589 ↓</span>  <span class="forward">0.2018 ↑</span></td>
              <td><span class="inverse">0.1953 ↓</span>  <span class="forward">0.2143 ↑</span></td>
              <td><span class="inverse">0.1666 ↓</span>  <span class="forward">0.2346 ↑</span></td>
            </tr>
            <tr>
              <td>Llama2-13B</td>
              <td><span class="inverse">0.1772 ↓</span>  <span class="forward">0.1958 ↑</span></td>
              <td><span class="inverse">0.2149 ↓</span>  <span class="forward">0.2408 ↑</span></td>
              <td><span class="inverse">0.1835 ↓</span>  <span class="forward">0.2345 ↑</span></td>
            </tr>
            <tr>
              <td>Llama3-8B</td>
              <td><span class="inverse">0.2540 ↓</span>  <span class="forward">0.2573 ↑</span></td>
              <td><span class="inverse">0.2268 ↓</span>  <span class="forward">0.3229 ↑</span></td>
              <td><span class="inverse">0.2341 ↓</span>  <span class="forward">0.2589 ↑</span></td>
            </tr>
            <tr>
              <td rowspan="3"><strong>TruthfulQA</strong></td>
              <td>Llama2-7B</td>
              <td><span class="inverse">0.1909 ↓</span>  <span class="forward">0.2069 ↑</span></td>
              <td><span class="inverse">0.1719 ↓</span>  <span class="forward">0.1721 ↑</span></td>
              <td><span class="inverse">0.2011 ↓</span>  <span class="forward">0.2542 ↑</span></td>
            </tr>
            <tr>
              <td>Llama2-13B</td>
              <td><span class="inverse">0.1704 ↓</span>  <span class="forward">0.1830 ↑</span></td>
              <td><span class="inverse">0.1544 ↓</span>  <span class="forward">0.1640 ↑</span></td>
              <td><span class="inverse">0.1825 ↓</span>  <span class="forward">0.2429 ↑</span></td>
            </tr>
            <tr>
              <td>Llama3-8B</td>
              <td><span class="inverse">0.2118 ↓</span>  <span class="forward">0.2256 ↑</span></td>
              <td><span class="inverse">0.2100 ↓</span>  <span class="forward">0.2173 ↑</span></td>
              <td><span class="inverse">0.2393 ↓</span>  <span class="forward">0.2898 ↑</span></td>
            </tr>
            <tr>
              <td rowspan="3"><strong>BeaverTails</strong></td>
              <td>Llama2-7B</td>
              <td><span class="inverse">0.2730 ↓</span>  <span class="forward">0.2809 ↑</span></td>
              <td><span class="inverse">0.2654 ↓</span>  <span class="forward">0.2691 ↑</span></td>
              <td><span class="inverse">0.2845 ↓</span>  <span class="forward">0.2883 ↑</span></td>
            </tr>
            <tr>
              <td>Llama2-13B</td>
              <td><span class="inverse">0.2419 ↓</span>  <span class="forward">0.2439 ↑</span></td>
              <td><span class="inverse">0.2320 ↓</span>  <span class="forward">0.2327 ↑</span></td>
              <td><span class="inverse">0.2464 ↓</span>  <span class="forward">0.2606 ↑</span></td>
            </tr>
            <tr>
              <td>Llama3-8B</td>
              <td><span class="inverse">0.2097 ↓</span>  <span class="forward">0.2156 ↑</span></td>
              <td><span class="inverse">0.2008 ↓</span>  <span class="forward">0.2427 ↑</span></td>
              <td><span class="inverse">0.2277 ↓</span>  <span class="forward">0.2709 ↑</span></td>
            </tr>
          </tbody>
        </table>
        
        <div class="key-finding">
          <strong>Key Result:</strong> <span class="inverse">Inverse alignment</span> consistently shows lower training loss than <span class="forward">forward alignment</span> across all models and datasets, confirming the <span class="resist">resistance</span> phenomenon.
        </div>
      </div>

      <div class="experiment-section" id="rebound-experiment">
        <h3>2. Evidence of <span class="rebound">Rebound</span> Phenomenon</h3>
        <div class="paragraph">
          We demonstrate that models trained with more positive data initially perform better but deteriorate faster when fine-tuned with negative data, exhibiting a characteristic <span class="rebound">rebound</span> pattern.
        </div>
        
        <img class="wide-img" src="static/images/exm_images/exp2.png" alt="Rebound Experiment Pipeline" style="max-width: 500px; margin: 20px auto; display: block;">
        
        <div class="experiment-vertical">
          <div class="experiment-item">
            <h4>IMDb Sentiment Task</h4>
            <img src="static/images/exm_images/exp_existence.png" alt="Rebound Results on IMDb">
            <p>Models with more positive training show faster performance decline under negative fine-tuning</p>
          </div>
          <div class="experiment-item">
            <h4>Safety Alignment Task</h4>
            <img src="static/images/exm_images/exp_existence.png" alt="Rebound Results on Safety">
            <p>Similar rebound patterns observed in safety-related alignment tasks</p>
          </div>
        </div>
      </div>

      <div class="experiment-section" id="model-size-experiment">
        <h3>3. Factors Affecting <span class="rebound">Rebound</span> Strength</h3>
        
        <h4 id="model-size-impact">3.1 Model Size Impact</h4>
        <div class="paragraph">
          Larger models exhibit stronger <span class="rebound">rebound</span> effects, with faster initial performance decline and slower subsequent decline.
        </div>
        
        <div class="experiment-grid">
          <div class="experiment-item">
            <h4>IMDb Task - Model Scaling</h4>
            <img src="static/images/exm_images/imdb_model_size.png" alt="Model Size Impact on IMDb">
            <p>0.5B → 4B → 7B parameter models show increasing rebound strength</p>
          </div>
          <div class="experiment-item">
            <h4>Safety Task - Model Scaling</h4>
            <img src="static/images/exm_images/safety_model_size.png" alt="Model Size Impact on Safety">
            <p>Consistent scaling behavior across different alignment objectives</p>
          </div>
        </div>

        <h4 id="data-volume-experiment">3.2 Pre-training Data Volume Impact</h4>
        <div class="paragraph">
          Models trained on larger pre-training datasets show enhanced <span class="rebound">rebound</span> effects, supporting our theoretical predictions.
        </div>
        
        <div class="experiment-grid">
          <div class="experiment-item">
            <h4>IMDb Task - Data Scaling</h4>
            <img src="static/images/exm_images/imdb_data.png" alt="Data Volume Impact on IMDb">
            <p>2.0T → 2.5T → 3.0T pre-training data shows increasing rebound</p>
          </div>
          <div class="experiment-item">
            <h4>Safety Task - Data Scaling</h4>
            <img src="static/images/exm_images/safety_data.png" alt="Data Volume Impact on Safety">
            <p>Larger pre-training datasets amplify resistance to alignment</p>
          </div>
        </div>
      </div>

      <h2 class="section-header" id="insights">Key Experimental Insights</h2>
      <div class="paragraph">
        <ul>
          <li><strong>Universal Phenomenon:</strong> <span class="resist">Resistance</span> and <span class="rebound">rebound</span> effects are observed consistently across different models (Llama2-7B/13B, Llama3-8B, Gemma-2B, Qwen series) and tasks</li>
          <li><strong>Scaling Behavior:</strong> Both model size and pre-training data volume positively correlate with elasticity strength</li>
          <li><strong>Algorithmic Independence:</strong> The phenomenon persists across different alignment methods (SFT, RLHF, DPO, KTO, SimPO)</li>
          <li><strong>Practical Implications:</strong> Even minimal negative fine-tuning can rapidly undo extensive positive alignment</li>
        </ul>
      </div>

      <h2 class="section-header" id="impact">Broader Impact</h2>
      <div class="paragraph">
        Our findings reveal fundamental challenges in language model alignment:
        <ul>
          <li><strong>Alignment Fragility:</strong> Current fine-tuning methods may only achieve superficial modifications</li>
          <li><strong>Open-source Risks:</strong> Advanced inverse alignment techniques could compromise even well-aligned models</li>
          <li><strong>Research Directions:</strong> Need for more robust alignment methods that achieve deeper, more persistent modifications</li>
        </ul>
      </div>

      <h2 class="section-header" id="citation">Citation</h2>
      <div class="citation">
        <pre id="codecell0">
@article{ji2024language,
  title={Language models resist alignment},
  author={Ji, Jiaming and Wang, Kaile and Qiu, Tianyi and Chen, Boyuan and Zhou, Jiayi and Li, Changye and Lou, Hantao and Yang, Yaodong},
  journal={arXiv preprint arXiv:2406.06144},
  year={2024}
}</pre>
      </div>
    </div>  

  </div>
  </div>

  <!-- JavaScript for navigation functionality -->
  <script>
    // Mobile menu toggle
    document.getElementById('mobile-toggle').addEventListener('click', function() {
      const navLinks = document.getElementById('nav-links');
      navLinks.classList.toggle('active');
    });

    // Left sidebar toggle
    document.getElementById('sidebar-toggle').addEventListener('click', function() {
      const sidebar = document.getElementById('left-sidebar');
      sidebar.classList.toggle('open');
    });

    // Smooth scrolling for all navigation links
    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
      anchor.addEventListener('click', function (e) {
        e.preventDefault();
        const target = document.querySelector(this.getAttribute('href'));
        if (target) {
          target.scrollIntoView({
            behavior: 'smooth',
            block: 'start'
          });
        }
        // Close mobile menu after clicking
        document.getElementById('nav-links').classList.remove('active');
        // Close sidebar on mobile after clicking
        if (window.innerWidth <= 1024) {
          document.getElementById('left-sidebar').classList.remove('open');
        }
      });
    });

    // Add scroll effect to navbar
    window.addEventListener('scroll', function() {
      const navbar = document.getElementById('navbar');
      if (window.scrollY > 50) {
        navbar.classList.add('scrolled');
      } else {
        navbar.classList.remove('scrolled');
      }
    });

    // Handle sidebar visibility on resize
    window.addEventListener('resize', function() {
      const sidebar = document.getElementById('left-sidebar');
      const sidebarToggle = document.getElementById('sidebar-toggle');
      
      if (window.innerWidth > 1024) {
        sidebar.classList.remove('open');
        sidebarToggle.classList.remove('visible');
      } else {
        sidebarToggle.classList.add('visible');
      }
    });

    // Initialize sidebar toggle visibility
    window.addEventListener('load', function() {
      const sidebarToggle = document.getElementById('sidebar-toggle');
      if (window.innerWidth <= 1024) {
        sidebarToggle.classList.add('visible');
      }
    });

    // Theory interaction functionality
    const proofContent = {
      'token-tree': {
        title: 'Token Tree Definition',
        content: `
          <p><strong>Motivation:</strong> The token tree provides a structured representation of all possible responses in a dataset, enabling us to model the compression process systematically.</p>
          
          <p><strong>Key Properties:</strong></p>
          <ul>
            <li>Each path from root to EOS represents a complete response</li>
            <li>Node weights represent probability masses</li>
            <li>Binary alphabet simplifies theoretical analysis</li>
            <li>Tree structure naturally encodes the autoregressive generation process</li>
          </ul>

                     <div class="math-block">
             <p><strong>Formal Structure:</strong></p>
             <p>For binary tokens {0, 1}, at depth d:</p>
             \\[\\text{Nodes at level } l: 2^{l-1}, \\quad l \\in \\{1, 2, \\ldots, d\\}\\]
             \\[\\sum_{\\text{all paths}} p_{\\text{path}} = 1\\]
           </div>

          <p><strong>Connection to Language Models:</strong> The token tree naturally represents the distribution learned by autoregressive language models, where each token prediction corresponds to choosing a branch in the tree.</p>
        `
      },
      'compression-protocol': {
        title: 'Compression Protocol Details',
        content: `
          <p><strong>Two-Stage Process:</strong></p>
          
          <p><strong>Stage 1: Tree Pruning</strong></p>
          <p>Due to finite model capacity, we can only perfectly model up to depth d. This reflects the practical limitation that language models cannot capture arbitrarily long dependencies.</p>
          
          <div class="math-block">
            \\[\\text{Pruned Tree: } \\mathcal{T}_{\\mathcal{D}}^{\\prime} = \\text{top } d \\text{ layers of } \\mathcal{T}_{\\mathcal{D}}\\]
          </div>

          <p><strong>Stage 2: Huffman Coding</strong></p>
          <p>Apply optimal prefix coding to the leaf nodes (complete responses) of the pruned tree.</p>

          <div class="math-block">
            <p><strong>Optimality:</strong> Huffman coding achieves the theoretical minimum:</p>
            \\[H(\\mathcal{P}) \\leq \\mathbb{E}[L] < H(\\mathcal{P}) + 1\\]
            where \\(H(\\mathcal{P})\\) is the Shannon entropy and \\(L\\) is the code length.
          </div>

          <p><strong>Why This Protocol?</strong></p>
          <ul>
            <li>Models training objective (minimize perplexity) ≡ minimize compression rate</li>
            <li>Huffman coding ensures optimality within the depth constraint</li>
            <li>Provides a principled way to compare model performance across datasets</li>
          </ul>
        `
      },
      'ideal-code-length': {
        title: 'Proof: Ideal Code Length',
        content: `
          <p><strong>Proof Strategy:</strong> We consider two cases based on sequence length relative to model depth d.</p>

          <p><strong>Case 1:</strong> \\(|\\mathbf{x}| \\leq d\\) (Perfect Compression)</p>
          <p>The model can perfectly represent the sequence within its depth limit.</p>
          
          <div class="math-block">
            \\[\\mathbb{E}[\\mathcal{L}_{p_{\\mathbf{\\theta}}}(\\mathbf{x})] = H(\\mathcal{P}_{\\text{leaf}}) = -\\sum_{l=1}^{d}\\sum_{j=1}^{2^{l-1}}p_{lj}\\log p_{lj}\\]
          </div>

          <p><strong>Case 2:</strong> \\(sd < |\\mathbf{x}| \\leq (s+1)d\\) (Segmented Compression)</p>
          <p>Split \\(\\mathbf{x} = (\\mathbf{x}_1, \\mathbf{x}_2, \\ldots, \\mathbf{x}_s, \\mathbf{x}_{s+1})\\) where \\(|\\mathbf{x}_i| = d\\) for \\(i \\leq s\\).</p>

          <div class="math-block">
            \\begin{align}
            \\mathbb{E}[\\mathcal{L}_{p_{\\mathbf{\\theta}}}(\\mathbf{x})] &= \\sum_{i=1}^{s+1} \\mathbb{E}[\\mathcal{L}_{p_{\\mathbf{\\theta}}}(\\mathbf{x}_i)] \\\\
            &= \\left\\lceil\\frac{|\\mathbf{x}|}{d}\\right\\rceil \\cdot H(\\mathcal{P}_{\\text{leaf}})
            \\end{align}
          </div>

          <p><strong>Key Insight:</strong> The ceiling function \\(\\lceil \\cdot \\rceil\\) accounts for the discrete nature of compression blocks, and segmentation is optimal due to the memoryless property of our compression protocol.</p>

          <p><strong>Practical Implication:</strong> This theorem establishes the fundamental relationship between model depth, sequence length, and compression efficiency - directly connecting to language model perplexity.</p>
        `
      },
      'inverse-alignment': {
        title: 'Inverse Alignment Concept',
        content: `
          <p><strong>Core Idea:</strong> Inverse alignment demonstrates that alignment can be undone with disproportionately small effort compared to the original alignment process.</p>

          <p><strong>Mathematical Formulation:</strong></p>
          <div class="math-block">
            \\[p_{\\mathbf{\\theta}_0} \\xrightarrow{\\mathcal{D}_a \\text{ (large)}} p_{\\mathbf{\\theta}_1} \\xrightarrow{\\mathcal{D}_b \\text{ (small)}} p_{\\mathbf{\\theta}_0^{\\prime}}\\]
            where \\(|\\mathcal{D}_b| \\ll |\\mathcal{D}_a|\\) but \\(\\rho(p_{\\mathbf{\\theta}_0^{\\prime}}, p_{\\mathbf{\\theta}_0}) \\leq \\epsilon\\)
          </div>

          <p><strong>Key Properties:</strong></p>
          <ul>
            <li><strong>Asymmetry:</strong> Forward alignment requires large dataset \\(\\mathcal{D}_a\\)</li>
            <li><strong>Efficiency:</strong> Inverse process needs only small dataset \\(\\mathcal{D}_b\\)</li>
            <li><strong>Effectiveness:</strong> Recovery is nearly complete (\\(\\rho \\leq \\epsilon\\))</li>
          </ul>

          <p><strong>Practical Significance:</strong></p>
          <ul>
            <li>Explains why aligned models can be easily "jailbroken"</li>
            <li>Highlights fragility of current alignment techniques</li>
            <li>Motivates need for more robust alignment methods</li>
          </ul>

          <p><strong>Connection to Elasticity:</strong> Inverse alignment is a manifestation of the underlying elasticity property - the model's tendency to revert to its pre-training distribution when perturbed.</p>
        `
      },
      'elasticity-definition': {
        title: 'Elasticity Definition Details',
        content: `
          <p><strong>Physical Analogy:</strong> Just as elastic materials return to their original shape after deformation, language models exhibit a tendency to revert to their pre-training distribution.</p>

          <p><strong>Mathematical Conditions:</strong></p>
          
          <div class="math-block">
            <p><strong>1. Algorithmic Simplicity:</strong> The inverse operation g should be computationally simple (e.g., standard fine-tuning).</p>
            <p><strong>2. Data Efficiency:</strong> \\(|\\mathcal{D}_b| \\ll |\\mathcal{D}_a|\\) - orders of magnitude difference.</p>
            <p><strong>3. Effectiveness:</strong> \\(\\rho(p_{\\mathbf{\\theta}_0^{\\prime}}, p_{\\mathbf{\\theta}_0}) \\leq \\epsilon_0\\) - near-perfect recovery.</p>
          </div>

          <p><strong>Components of Elasticity:</strong></p>
          <ul>
            <li><span class="resist"><strong>Resistance:</strong></span> Initial reluctance to change from pre-training distribution</li>
            <li><span class="rebound"><strong>Rebound:</strong></span> Tendency to return to original state under perturbation</li>
          </ul>

          <p><strong>Theoretical Foundation:</strong> Elasticity emerges from the fundamental asymmetry in dataset sizes:</p>
          <div class="math-block">
            \\[|\\mathcal{D}_{\\text{pre-train}}| \\gg |\\mathcal{D}_{\\text{alignment}}| \\gg |\\mathcal{D}_{\\text{perturbation}}|\\]
          </div>

          <p><strong>Implications:</strong></p>
          <ul>
            <li>Current alignment methods may be fundamentally limited</li>
            <li>Need for alignment techniques that account for elasticity</li>
            <li>Importance of understanding pre-training's lasting influence</li>
          </ul>
        `
      },
      'normalized-compression': {
        title: 'Normalized Compression Rate',
        content: `
          <p><strong>Motivation:</strong> Raw compression rates are not directly comparable across datasets of different sizes and complexities. Normalization enables fair comparison.</p>

          <p><strong>Normalization Process:</strong></p>
          <div class="math-block">
            \\[\\gamma_{p_{\\mathbf{\\theta}}}^{\\mathcal{D}_{i}/\\mathcal{D}} = \\gamma_{p_{\\mathbf{\\theta}}}^{\\mathcal{D}_{i}} - \\log M\\]
          </div>

          <p><strong>Why Subtract log M?</strong></p>
          <ul>
            <li>\\(M\\) = number of possible outcomes (leaf nodes)</li>
            <li>\\(\\log M\\) = uniform distribution entropy</li>
            <li>Normalization removes baseline complexity</li>
            <li>Enables comparison of model's compression improvement</li>
          </ul>

          <p><strong>Interpretation:</strong></p>
          <div class="math-block">
            <p><strong>Compression Gain:</strong></p>
            \\[\\text{Gain} = \\log M - \\gamma_{p_{\\mathbf{\\theta}}}^{\\mathcal{D}_{i}} = -\\gamma_{p_{\\mathbf{\\theta}}}^{\\mathcal{D}_{i}/\\mathcal{D}}\\]
          </div>

          <p><strong>Properties:</strong></p>
          <ul>
            <li><strong>Lower values</strong> = better compression = better model fit</li>
            <li><strong>Negative values</strong> = compression better than uniform</li>
            <li><strong>Cross-dataset comparison</strong> = meaningful relative performance</li>
          </ul>

          <p><strong>Connection to Perplexity:</strong> The normalized compression rate is directly related to model perplexity, providing a information-theoretic foundation for model evaluation.</p>
        `
      },
      'main-theorem': {
        title: 'Proof: Elasticity of Language Models',
        content: `
          <p><strong>Proof Overview:</strong> We demonstrate that compression rate changes are inversely proportional to dataset sizes, creating "elastic" behavior in language models when perturbation data is introduced.</p>

          <p><strong>Step 1: Setup & Assumptions</strong></p>
          <p>Consider pre-training dataset \\(\\mathcal{D}_p = \\bigcup_{i=1}^{3}\\mathcal{D}_{i}\\), alignment dataset \\(\\mathcal{D}_a\\), and perturbation dataset \\(\\mathcal{D}_t\\) with Pareto mass distributions:</p>
          <div class="math-block">
            \\[p_X(x) = \\frac{\\alpha c^\\alpha}{x^{\\alpha+1}}, \\quad x \\geq c\\]
          </div>

          <p><strong>Step 2: Transform to Mass Distribution</strong></p>
          <p>Using Lemma (Entropy of Mass Distribution), we replace Shannon entropy with mass distribution:</p>
          <div class="math-block">
            \\[\\frac{d\\gamma_{p_{\\boldsymbol{\theta}}}^{\\mathcal{D}_j/\\mathcal{D}}}{dl} = \\frac{d\\left(\\mathbb{E}_{X_{\\mathcal{D}_{j}}\\sim\\mathcal{P}_{mass}^{j},X_{\\mathcal{D}}\\sim\\mathcal{P}_{mass}}\\left[-X_{\\mathcal{D}_{j}}\\log{X_{\\mathcal{D}}}\\right]\\right)}{dl}\\]
          </div>

          <p><strong>Step 3: Key Integrals</strong></p>
          <p>For pre-training and alignment datasets:</p>
          <div class="math-block">
            \\begin{align}
            S_1 &= \\int_{c}^{+\\infty} \\int_{c}^{+\\infty} \\int_{c}^{+\\infty} \\frac{\\alpha^3 c^{3\\alpha}(x_1+x_2+x_3)}{3x_{1}^{\\alpha+1} x_{2}^{\\alpha+1} x_{3}^{\\alpha+1}}\\log{\\frac{\\frac{k}{3}(x_{1}+x_2+x_3)+x_{2}+lx_3}{k+l+1}}dx_1dx_2dx_3 \\\\
            S_2 &= \\int_{c}^{+\\infty} \\int_{c}^{+\\infty} \\int_{c}^{+\\infty} \\frac{\\alpha^3 c^{3\\alpha}}{x_{1}^{\\alpha+1} x_{2}^{\\alpha} x_{3}^{\\alpha+1}}\\log{\\frac{\\frac{k}{3}(x_{1}+x_2+x_3)+x_{2}+lx_3}{k+l+1}}dx_1dx_2dx_3
            \\end{align}
          </div>

          <p><strong>Step 4: Asymptotic Analysis</strong></p>
          <p>As \\(k \\to +\\infty\\) (large pre-training data) and \\(l \\to 0\\) (small perturbation):</p>
          <div class="math-block">
            \\[\\lim_{k \\to +\\infty, l \\to 0} \\frac{k \\cdot \\frac{d\\gamma_{p_{\\boldsymbol{\theta}}}^{\\mathcal{D}_p/\\mathcal{D}}}{dl} + \\frac{d\\gamma_{p_{\\boldsymbol{\theta}}}^{\\mathcal{D}_a/\\mathcal{D}}}{dl}}{k \\cdot \\frac{d\\gamma_{p_{\\boldsymbol{\theta}}}^{\\mathcal{D}_p/\\mathcal{D}}}{dl}} = 0\\]
          </div>

          <p><strong>Step 5: Physical Interpretation</strong></p>
          <p>The elasticity relationship shows:</p>
          <div class="math-block">
            \\[|\\mathcal{D}_p| \\cdot \\Delta\\gamma_p \\approx |\\mathcal{D}_a| \\cdot \\Delta\\gamma_a = \\text{constant}\\]
          </div>

          <p><strong>Spring Analogy:</strong> Like Hooke's law \\(F = k \\Delta l\\), we have \\(F \\propto |\\mathcal{D}| \\cdot \\Delta\\gamma\\), where dataset size acts as the "spring constant" and compression rate change as "deformation". This explains why large pre-training datasets create strong resistance to alignment changes.</p>
        `
      }
    };

    function showProof(theoryId) {
      // Remove active class from all theory items
      document.querySelectorAll('.theory-item').forEach(item => {
        item.classList.remove('active');
      });
      
      // Add active class to clicked item
      const clickedItem = document.querySelector(`[data-theory="${theoryId}"]`);
      if (clickedItem) {
        clickedItem.classList.add('active');
      }
      
      // Update proof panel
      const proofContainer = document.getElementById('proof-container');
      const proof = proofContent[theoryId];
      
      // Determine if it's a definition or theorem
      const definitionTheories = ['token-tree', 'compression-protocol', 'inverse-alignment', 'elasticity-definition', 'normalized-compression'];
      const theoremTheories = ['ideal-code-length', 'main-theorem'];
      
      if (proof) {
        // Clear previous theme classes
        proofContainer.classList.remove('definition-active');
        
        let headerClass = 'proof-header';
        let mathBlockClass = '';
        
        if (definitionTheories.includes(theoryId)) {
          proofContainer.classList.add('definition-active');
          headerClass += ' definition-header';
          mathBlockClass = ' definition-math';
        }
        
        let content = proof.content;
        // Add appropriate math-block classes
        if (mathBlockClass) {
          content = content.replace(/class="math-block"/g, `class="math-block${mathBlockClass}"`);
        }
        
        proofContainer.innerHTML = `
          <div class="${headerClass}">${proof.title}</div>
          <div class="proof-content">${content}</div>
        `;
        proofContainer.classList.add('active');
        
        // Re-render MathJax for the new content
        if (window.MathJax) {
          MathJax.typesetPromise([proofContainer]).catch((err) => console.log(err.message));
        }
      }
    }

    // Highlight active section in navigation
    window.addEventListener('scroll', function() {
      const sections = [
        'top', 'overview', 'theory', 'token-tree', 'compression-protocol', 
        'ideal-code-length', 'inverse-alignment', 'elasticity-definition', 
        'normalized-compression', 'main-theorem', 'experiments', 
        'resistance-experiment', 'rebound-experiment', 'model-size-experiment', 
        'data-volume-experiment', 'insights', 'impact', 'citation'
      ];
      
      const topNavLinks = document.querySelectorAll('.nav-links a');
      const sidebarLinks = document.querySelectorAll('.sidebar-nav a');
      
      let current = '';
      sections.forEach(sectionId => {
        const section = document.getElementById(sectionId);
        if (section) {
          const rect = section.getBoundingClientRect();
          if (rect.top <= 150 && rect.bottom >= 150) {
            current = sectionId;
          }
        }
      });

      // Update top navigation
      topNavLinks.forEach(link => {
        link.classList.remove('active');
        if (link.getAttribute('data-section') === current) {
          link.classList.add('active');
        }
      });

      // Update sidebar navigation
      sidebarLinks.forEach(link => {
        link.classList.remove('active');
        const href = link.getAttribute('href');
        if (href === `#${current}`) {
          link.classList.add('active');
        }
      });
    });
  </script>
</body>

</html>
