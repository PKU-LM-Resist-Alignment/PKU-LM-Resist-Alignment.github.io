<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta content="Language Models Resist Alignment: Evidence From Data Compression" name="description" />
  <meta content="Language Models Resist Alignment: Evidence From Data Compression" property="og:title" />
  <meta content="Language Models Resist Alignment: Evidence From Data Compression" property="og:description" />
  <meta content="https://pku-lm-resist-alignment.github.io/data/open_graph.png" property="og:image" />
  <meta content="Language Models Resist Alignment" property="twitter:title" />
  <meta content="Language Models Resist Alignment" property="twitter:description" />
  <meta name="twitter:site" content="@jiaming_pku" />
  <meta name="twitter:creator" content="@jiaming_pku" />
  <meta content="https://pku-lm-resist-alignment.github.io/data/open_graph.png" property="twitter:image" />
  <meta property="og:type" content="website" />
  <meta content="summary_large_image" name="twitter:card" />
  <meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />

  <title>Language Models Resist Alignment: Evidence From Data Compression</title>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-9Z7HCWJNBC"></script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
  </script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', 'G-9Z7HCWJNBC');
  </script>
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link rel="preload" as="style"
    href="https://fonts.googleapis.com/css2?family=Asap:wght@700&family=Source+Sans+3:wght@400;700&display=swap">
  <link rel="stylesheet"
    href="https://fonts.googleapis.com/css2?family=Asap:wght@700&family=Source+Sans+3:wght@400;700&display=swap">
  <link href="style.css" rel="stylesheet" type="text/css" />
</head>

<body>


  <div class="section">
    <div class="container">
      <div class="title-row">
        <h1 class="title">Language Models Resist Alignment: Evidence From Data Compression<h1>
      </div>
      <div class="row">
        <div class="author-col">
          <a href="https://jijiaming.com/" target="_blank" class="author-text">
            Jiaming Ji*
          </a>
        </div>
        <div class="author-col">
          <a href="https://scholar.google.com.hk/citations?user=hTNgG1YAAAAJ" target="_blank" class="author-text">
            Kaile Wang*
          </a>
        </div>
        <div class="invisible"><br></div>
        <div class="author-col">
          <a href="https://tianyiqiu.net" target="_blank" class="author-text">
            Tianyi Qiu*
          </a>
        </div>
        <div class="author-col">
          <a href="https://cby-pku.github.io/" target="_blank" class="author-text">
            Boyuan Chen<span class="superscript">*</span>
          </a>
        </div>
        <div class="author-col">
          <a href="https://gaiejj.github.io" target="_blank" class="author-text">
            Jiayi Zhou*
          </a>
        </div>
      </div>
      <div class="row">
        <div class="author-col">
          <a class="author-text">
            Changye Li
          </a>
        </div>
        <div class="author-col">
          <a class="author-text">
            Hantao Lou
          </a>
        </div>
        <div class="author-col">
          <a class="author-text">
            Juntao Dai
          </a>
        </div>
        <div class="author-col">
          <a class="author-text">
            Yunhuai Liu
          </a>
        </div>
        <div class="author-col">
          <a href="https://www.yangyaodong.com/" target="_blank" class="author-text">
            Yaodong Yang<span class="superscript">†</span>
          </a>
        </div>
      </div>

    </div>
    <p id="uc-berkeley">Peking University</h1>

    <div class="row button-row">
      <a class="link-button" href="https://arxiv.org/abs/2406.06144" target="_blank" class="link-block">Paper</a>
      <a class="link-button" href="https://github.com/PKU-Alignment/llms-resist-alignment" class="link-block">Code</a>
      <a class="link-button"
        href="https://huggingface.co/collections/PKU-Alignment/language-model-resist-alignment-683aa526612e76702e7651ae"
        class="link-block">Models</a>
    </div>
    <p class="tldr">
      <b>TL;DR</b>:
      We demonstrate the elasticity of post-alignment models, forming resistance to alignment.
    </p>

    <div id="content">
      <h2 class="section-header">Overview</h2>
      <div class="paragraph">
        <p>
          Large language models (LLMs) may exhibit unintended or undesirable behaviors. Recent works have concentrated
          on aligning LLMs to mitigate harmful outputs. Despite these efforts, some anomalies indicate that even a
          well-conducted alignment process can be easily circumvented, whether intentionally or accidentally. Does
          alignment fine-tuning yield have robust effects on models, or are its impacts merely
          <i><b>superficial?</b></i> In
          this work, we make the first exploration of this phenomenon from both theoretical and empirical perspectives.
          Empirically, we demonstrate the <i><b>elasticity</b></i> of post-alignment models, <i>i.e.</i>, the tendency
          to
          revert to the behavior distribution formed during the pre-training phase upon further fine-tuning. Leveraging
          compression theory, we formally deduce that fine-tuning disproportionately undermines alignment
          relative to pre-training, potentially by orders of magnitude. We validate the presence of <i>elasticity</i>
          through experiments on models of varying types and scales. Specifically, we find that model performance
          declines rapidly before reverting to the pre-training
          distribution, after which the rate of decline drops significantly. Furthermore, we further reveal that
          <i>elasticity</i> positively correlates with the increased model size
          and the expansion of pre-training data. Our findings underscore the need to address the inherent
          <i>elasticity</i> of LLMs to mitigate their
          resistance to alignment.
        </p>
        <p><b>Contributions:</b></p>
        <ul>
          <li>
            <b>Phenomenon:</b> we uncover that language models exhibit <i>elasticity</i>. It encompasses
            <span class="resist">resistance</span>: pre-trained models tend
            to retain their original distribution; and <span class="rebound">rebound</span>: the deeper alignment of
            models, the faster
            they return to the pre-trained distribution under reverse finetuning. Moreover, The model’s change in
            compression rates \(\Delta \gamma_{p_\mathbf{\theta}}^{\mathcal{D}_i/\mathcal{D}}\) across
            different datasets is inversely proportional to their sizes \(|\mathcal{D}_i|\), which is
            analogous to the deformation behavior of a series of springs.

          </li>
          <li>
            <b>Mechanism:</b> We systematically model the training and alignment process of language models through
            compression theorem. We elaborate on the compression
            protocol of language models to explore their training and alignment processes, laying a foundation for
            subsequent research on <i>elasticity</i>.
          </li>
          <li>
            <b>Validation:</b> We experimentally observe consistent resistance and rebound phenomena
            across various LLMs. This highlights the universality of elasticity and the need for systematic approaches
            to achieve robust and deep alignment.
          </li>
        </ul>
      </div>
      <h2 class="section-header">Citation</h2>
      <div class="citation">
        <pre id="codecell0">
@article{ji2024language,
  title={Language models resist alignment},
  author={Ji, Jiaming and Wang, Kaile and Qiu, Tianyi and Chen, Boyuan and Zhou, Jiayi and Li, Changye and Lou, Hantao and Yang, Yaodong},
  journal={arXiv preprint arXiv:2406.06144},
  year={2024}
}</pre>
      </div>
    </div>  

  </div>
</body>

</html>